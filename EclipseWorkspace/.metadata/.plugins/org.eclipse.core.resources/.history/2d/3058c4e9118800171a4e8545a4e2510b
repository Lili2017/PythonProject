#coding=utf-8
'''
Created on 2017��8��23��

@author: LIli
'''
import urllib2
import urllib
from bs4 import BeautifulSoup
import csv
import re
import sys
reload(sys)
sys.setdefaultencoding('utf-8')


page = 1
url = 'http://sh.fang.lianjia.com/loupan/pg' + str(page)
user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'
headers = { 'User-Agent' : user_agent }
try:
    request = urllib2.Request(url,headers = headers)
    response = urllib2.urlopen(request)
    the_page = response.read()
    soup = BeautifulSoup(the_page,"lxml")
    list0=[]
    list1=[]
    list2=[]
    list3=[]
    list4=[]
    list5=[]
    list6=[]
    for tag in soup.find_all(name="div", attrs={"class": re.compile("col-1")}):
        ta1 = tag.find(name="a", attrs={"target": re.compile("_blank")})
        #��ӳ����ֶ�
        list0.append('�Ϻ�')
        list1.append(ta1.string)
     #��ȡ��������ֶ�
        ta2 = tag.find(name="a", attrs={"class": re.compile("area")})
        if ta2 != None:
            list2.append(ta2.string)
        else:
            list2.append(0)
        #��ȡ����״̬�ֶ�
        ta3 = tag.find(name="span", attrs={"class": re.compile("onsold")})
        list3.append(ta3.string)
       #��ȡסլ�����ֶ�
        ta4 = tag.find(name="span", attrs={"class": re.compile("live")})
        list4.append(ta4.string)
#��ȡÿƽ�׾����ֶ�
    for tag in soup.find_all(name="div", attrs={"class": re.compile("col-2")}):
        ta5 = tag.find(name="span", attrs={"class": re.compile("num")})
        if ta5 != None:
             list5.append(ta5.string)
        else:
            list5.append(0)
       #��ȡ�ܼ��ֶ�
        ta6 = tag.find(name="div", attrs={"class": re.compile("sum-num")})
        if ta6 !=None:
            t6 = ta6.find(name="span")
            list6.append(t6.string)
        else:
            list6.append(0)
    
    csvfile = file(r'C:\Users\LIli\Desktop\lianjia.csv', 'ab+')
    writer = csv.writer(csvfile)    
    data = []
    for i in range(0,len(list0)):
        data.append((list0[i],list1[i], list2[i], list3[i], list4[i], list5[i],list6[i]))
        writer.writerows(data)
    csvfile.close()
    
except urllib2.URLError, e:
    if hasattr(e,"code"):
        print e.code
    if hasattr(e,"reason"):
        print e.reason
        
    